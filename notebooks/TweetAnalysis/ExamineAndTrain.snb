{
  "metadata" : {
    "name" : "ExamineAndTrain",
    "user_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "customLocalRepo" : "/home/automaton/.ivy2",
    "customRepos" : null,
    "customDeps" : [ "com.datastax.spark:spark-cassandra-connector_2.10:1.4.0-M3", "- org.apache.spark % spark-core_2.10 % _", "com.databricks:spark-csv_2.10:1.2.0", "- org.apache.hadoop % _ % _", "org.twitter4j:twitter4j-core:3.0.3", "com.google.code.gson:gson:2.3", "org.apache.spark:spark-streaming-twitter_2.10:1.4.0" ],
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : {
      "spark.cassandra.connection.host" : "172.31.21.172",
      "spark.master" : "spark://172.31.21.172:7077",
      "spark.executor.cores" : "2",
      "spark.executor.memory" : "4G",
      "spark.cores.max" : "5",
      "spark.eventLog.enabled" : "true",
      "spark.eventLog.dir" : "logs/spark"
    }
  },
  "cells" : [ {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "### Setup the SQL Context and necessary imports"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val sqlContext = new org.apache.spark.sql.SQLContext(sparkContext)\nimport sqlContext.implicits._\nimport org.apache.spark.sql.functions._\nimport com.datastax.spark.connector.cql.CassandraConnector\n\nimport com.datastax.spark.connector._\nimport com.datastax.spark.connector.streaming._\n\nimport java.util.concurrent.atomic.AtomicInteger\n\nimport com.google.gson.Gson\nimport org.apache.spark.streaming.twitter.TwitterUtils\nimport org.apache.spark.streaming.{Seconds, StreamingContext}\nimport org.apache.spark.{SparkConf, SparkContext}\n\nimport com.datastax.spark.connector._\n",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "sqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@39437cf4\nimport sqlContext.implicits._\nimport org.apache.spark.sql.functions._\nimport com.datastax.spark.connector.cql.CassandraConnector\nimport com.datastax.spark.connector._\nimport com.datastax.spark.connector.streaming._\nimport java.util.concurrent.atomic.AtomicInteger\nimport com.google.gson.Gson\nimport org.apache.spark.streaming.twitter.TwitterUtils\nimport org.apache.spark.streaming.{Seconds, StreamingContext}\nimport org.apache.spark.{SparkConf, SparkContext}\nimport com.datastax.spark.connector._\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 1
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val tweets = sc.cassandraTable(\"tweet_db\", \"raw_tweets\")\ntweets.take(5)",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "tweets: com.datastax.spark.connector.rdd.CassandraTableScanRDD[com.datastax.spark.connector.CassandraRow] = CassandraTableScanRDD[0] at RDD at CassandraRDD.scala:15\nres2: Array[com.datastax.spark.connector.CassandraRow] = Array(CassandraRow{tweet_id: 646349590661332992, raw_tweet: RT @istanbulltd: @KukreyenKurba @YUSUFYAKUB622 Allah'ın adıyla basla sen bu kitaba. Pirense doncen aq http://t.co/7xnlMlWkOw}, CassandraRow{tweet_id: 646146871547658240, raw_tweet: Saya salah satunya,, kwkw\"@tetyedeswita: Pecinta paling tulus tak pernah menuntut agar orang yang ia cintai segera memahami perasaannya. :)\"}, CassandraRow{tweet_id: 646146506622390272, raw_tweet: First episode of Wabbit was alright. First short suffered from being very predictable though}, CassandraRow{tweet_id: 646349565474566144,..."
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon83bf1754d36b71723467609ddd25e137&quot;,&quot;dataInit&quot;:[{&quot;X&quot;:&quot;WrappedArray(tweet_id, raw_tweet)&quot;,&quot;Y&quot;:&quot;WrappedArray(646349590661332992, RT @istanbulltd: @KukreyenKurba @YUSUFYAKUB622 Allah'ın adıyla basla sen bu kitaba. Pirense doncen aq http://t.co/7xnlMlWkOw)&quot;},{&quot;X&quot;:&quot;WrappedArray(tweet_id, raw_tweet)&quot;,&quot;Y&quot;:&quot;WrappedArray(646146871547658240, Saya salah satunya,, kwkw\\&quot;@tetyedeswita: Pecinta paling tulus tak pernah menuntut agar orang yang ia cintai segera memahami perasaannya. :)\\&quot;)&quot;},{&quot;X&quot;:&quot;WrappedArray(tweet_id, raw_tweet)&quot;,&quot;Y&quot;:&quot;WrappedArray(646146506622390272, First episode of Wabbit was alright. First short suffered from being very predictable though)&quot;},{&quot;X&quot;:&quot;WrappedArray(tweet_id, raw_tweet)&quot;,&quot;Y&quot;:&quot;WrappedArray(646349565474566144, @hometownoffic I ain't gonna be there 👺)&quot;},{&quot;X&quot;:&quot;WrappedArray(tweet_id, raw_tweet)&quot;,&quot;Y&quot;:&quot;WrappedArray(646146657617219584, RT @Gwonam: Hello Twitter! #myfirstTweet)&quot;}],&quot;genId&quot;:&quot;1328724682&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/tabs'], \n      function(playground, _magictabs) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magictabs,\n    \"o\": {}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    <div>\n        <ul class=\"nav nav-tabs\" id=\"ul1328724682\"><li>\n              <a href=\"#tab1328724682-0\"><i class=\"fa fa-table\"/></a>\n            </li><li>\n              <a href=\"#tab1328724682-1\"><i class=\"fa fa-pie-chart\"/></a>\n            </li></ul>\n\n        <div class=\"tab-content\" id=\"tab1328724682\"><div class=\"tab-pane\" id=\"tab1328724682-0\">\n            <div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anond1fd61f5d5c66d3cd2c2b12c8a4bf7b6&quot;,&quot;dataInit&quot;:[{&quot;X&quot;:&quot;WrappedArray(tweet_id, raw_tweet)&quot;,&quot;Y&quot;:&quot;WrappedArray(646349590661332992, RT @istanbulltd: @KukreyenKurba @YUSUFYAKUB622 Allah'ın adıyla basla sen bu kitaba. Pirense doncen aq http://t.co/7xnlMlWkOw)&quot;},{&quot;X&quot;:&quot;WrappedArray(tweet_id, raw_tweet)&quot;,&quot;Y&quot;:&quot;WrappedArray(646146871547658240, Saya salah satunya,, kwkw\\&quot;@tetyedeswita: Pecinta paling tulus tak pernah menuntut agar orang yang ia cintai segera memahami perasaannya. :)\\&quot;)&quot;},{&quot;X&quot;:&quot;WrappedArray(tweet_id, raw_tweet)&quot;,&quot;Y&quot;:&quot;WrappedArray(646146506622390272, First episode of Wabbit was alright. First short suffered from being very predictable though)&quot;},{&quot;X&quot;:&quot;WrappedArray(tweet_id, raw_tweet)&quot;,&quot;Y&quot;:&quot;WrappedArray(646349565474566144, @hometownoffic I ain't gonna be there 👺)&quot;},{&quot;X&quot;:&quot;WrappedArray(tweet_id, raw_tweet)&quot;,&quot;Y&quot;:&quot;WrappedArray(646146657617219584, RT @Gwonam: Hello Twitter! #myfirstTweet)&quot;}],&quot;genId&quot;:&quot;1074167899&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/tableChart'], \n      function(playground, _magictableChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magictableChart,\n    \"o\": {\"headers\":[\"X\",\"Y\"],\"nrow\":5,\"shown\":5,\"width\":600,\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    </div>\n            </div><div class=\"tab-pane\" id=\"tab1328724682-1\">\n            <div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon2a17aedfee323e3b69223ec5b3792d93&quot;,&quot;dataInit&quot;:[{&quot;X&quot;:&quot;WrappedArray(tweet_id, raw_tweet)&quot;,&quot;Y&quot;:&quot;WrappedArray(646349590661332992, RT @istanbulltd: @KukreyenKurba @YUSUFYAKUB622 Allah'ın adıyla basla sen bu kitaba. Pirense doncen aq http://t.co/7xnlMlWkOw)&quot;},{&quot;X&quot;:&quot;WrappedArray(tweet_id, raw_tweet)&quot;,&quot;Y&quot;:&quot;WrappedArray(646146871547658240, Saya salah satunya,, kwkw\\&quot;@tetyedeswita: Pecinta paling tulus tak pernah menuntut agar orang yang ia cintai segera memahami perasaannya. :)\\&quot;)&quot;},{&quot;X&quot;:&quot;WrappedArray(tweet_id, raw_tweet)&quot;,&quot;Y&quot;:&quot;WrappedArray(646146506622390272, First episode of Wabbit was alright. First short suffered from being very predictable though)&quot;},{&quot;X&quot;:&quot;WrappedArray(tweet_id, raw_tweet)&quot;,&quot;Y&quot;:&quot;WrappedArray(646349565474566144, @hometownoffic I ain't gonna be there 👺)&quot;},{&quot;X&quot;:&quot;WrappedArray(tweet_id, raw_tweet)&quot;,&quot;Y&quot;:&quot;WrappedArray(646146657617219584, RT @Gwonam: Hello Twitter! #myfirstTweet)&quot;}],&quot;genId&quot;:&quot;912123141&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/pieChart'], \n      function(playground, _magicpieChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magicpieChart,\n    \"o\": {\"series\":\"X\",\"p\":\"Y\",\"width\":600,\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    </div>\n            </div></div>\n      </div></div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 2
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : ":markdown\nThere are **${tweets.count}** tweets",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "res3: String = There are **32221** tweets\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/markdown" : "There are **32221** tweets"
      },
      "output_type" : "execute_result",
      "execution_count" : 3
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val tweetTable = sqlContext.read.format(\"org.apache.spark.sql.cassandra\")\n                    .options(Map( \"keyspace\" -> \"tweet_db\", \"table\" -> \"raw_tweets\"))\n                    .load()\n\ntweetTable.registerTempTable(\"tweetTable\")\n\ntweetTable",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "tweetTable: org.apache.spark.sql.DataFrame = [tweet_id: bigint, raw_tweet: string]\nres4: org.apache.spark.sql.DataFrame = [tweet_id: bigint, raw_tweet: string]\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div class=\"df-canvas\">\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon104ee852a999f1c1759873f6d4c7f487&quot;,&quot;partitionIndexId&quot;:&quot;anon7ae28d120440619edf9ae0e3f782c683&quot;,&quot;numPartitions&quot;:1305,&quot;dfSchema&quot;:{&quot;type&quot;:&quot;struct&quot;,&quot;fields&quot;:[{&quot;name&quot;:&quot;tweet_id&quot;,&quot;type&quot;:&quot;long&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}},{&quot;name&quot;:&quot;raw_tweet&quot;,&quot;type&quot;:&quot;string&quot;,&quot;nullable&quot;:true,&quot;metadata&quot;:{}}]}}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/dataframe','../javascripts/notebook/consoleDir'], \n      function(dataframe, extension) {\n        dataframe.call(data, this, extension);\n      }\n    );/*]]>*/</script>\n      <link rel=\"stylesheet\" href=\"/assets/stylesheets/ipython/css/dataframe.css\" type=\"text/css\"/>\n    </div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 4
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "tweetTable.printSchema()",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "root\n |-- tweet_id: long (nullable = true)\n |-- raw_tweet: string (nullable = true)\n\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 5
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val texts = tweetTable.rdd.map(row => row.getString(1))\ntexts.take(5)",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "texts: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[9] at map at <console>:72\nres6: Array[String] = Array(RT @istanbulltd: @KukreyenKurba @YUSUFYAKUB622 Allah'ın adıyla basla sen bu kitaba. Pirense doncen aq http://t.co/7xnlMlWkOw, Saya salah satunya,, kwkw\"@tetyedeswita: Pecinta paling tulus tak pernah menuntut agar orang yang ia cintai segera memahami perasaannya. :)\", First episode of Wabbit was alright. First short suffered from being very predictable though, @hometownoffic I ain't gonna be there 👺, RT @Gwonam: Hello Twitter! #myfirstTweet)\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div class=\"container-fluid\"><div><div class=\"col-md-12\"><div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon62d190bd3d2dd93221a656b1c100bd23&quot;,&quot;dataInit&quot;:[{&quot;string value&quot;:&quot;RT @istanbulltd: @KukreyenKurba @YUSUFYAKUB622 Allah'ın adıyla basla sen bu kitaba. Pirense doncen aq http://t.co/7xnlMlWkOw&quot;},{&quot;string value&quot;:&quot;Saya salah satunya,, kwkw\\&quot;@tetyedeswita: Pecinta paling tulus tak pernah menuntut agar orang yang ia cintai segera memahami perasaannya. :)\\&quot;&quot;},{&quot;string value&quot;:&quot;First episode of Wabbit was alright. First short suffered from being very predictable though&quot;},{&quot;string value&quot;:&quot;@hometownoffic I ain't gonna be there 👺&quot;},{&quot;string value&quot;:&quot;RT @Gwonam: Hello Twitter! #myfirstTweet&quot;}],&quot;genId&quot;:&quot;956333341&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/tableChart'], \n      function(playground, _magictableChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magictableChart,\n    \"o\": {\"headers\":[\"string value\"],\"nrow\":5,\"shown\":5,\"width\":600,\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    </div></div></div></div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 6
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "import org.apache.spark.mllib.linalg.{Vector, SparseVector}\nimport org.apache.spark.mllib.feature.HashingTF\n\nval numFeatures = 1000\nval tf = new HashingTF(numFeatures)\n\n/**\n   * Create feature vectors by turning each tweet into bigrams of characters (an n-gram model)\n   * and then hashing those to a length-1000 feature vector that we can pass to MLlib.\n   * This is a common way to decrease the number of features in a model while still\n   * getting excellent accuracy (otherwise every pair of Unicode characters would\n   * potentially be a feature).\n   */\n  def featurize(s: String): Vector = {\n    tf.transform(s.sliding(2).toSeq)\n  }",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark.mllib.linalg.{Vector, SparseVector}\nimport org.apache.spark.mllib.feature.HashingTF\nnumFeatures: Int = 1000\ntf: org.apache.spark.mllib.feature.HashingTF = org.apache.spark.mllib.feature.HashingTF@1a116a93\nfeaturize: (s: String)org.apache.spark.mllib.linalg.Vector\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 7
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val vectors = texts.map(featurize).cache()\nvectors.count() \nvectors.take(10)",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "vectors: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = MapPartitionsRDD[10] at map at <console>:82\nres7: Array[org.apache.spark.mllib.linalg.Vector] = Array((1000,[39,53,56,57,59,72,73,89,90,92,96,99,100,105,107,111,117,120,122,123,135,155,158,163,170,180,211,241,252,259,263,340,369,370,371,396,405,410,422,425,431,435,442,445,456,458,464,485,488,495,504,508,509,512,514,518,525,530,535,551,565,568,573,576,582,585,600,626,632,635,636,642,658,659,666,673,681,693,696,701,705,708,712,718,724,734,735,741,804,824,825,830,844,845,852,859],[3.0,1.0,3.0,1.0,1.0,1.0,1.0,3.0,3.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,1.0,1.0,3.0,2.0,1.0,1.0,1.0,1.0,1.0,4.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,5.0,3.0,2.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,1.0,1.0,..."
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div class=\"container-fluid\"><div><div class=\"col-md-12\"><div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon71b2aef0c8378b023cfbed6a9b5dc256&quot;,&quot;dataInit&quot;:[{&quot;size&quot;:1000,&quot;indices&quot;:&quot;[I@5745ed23&quot;,&quot;values&quot;:&quot;[D@4acf7a1e&quot;},{&quot;size&quot;:1000,&quot;indices&quot;:&quot;[I@747d9296&quot;,&quot;values&quot;:&quot;[D@6cd41b9c&quot;},{&quot;size&quot;:1000,&quot;indices&quot;:&quot;[I@1480dfd0&quot;,&quot;values&quot;:&quot;[D@25ae58d4&quot;},{&quot;size&quot;:1000,&quot;indices&quot;:&quot;[I@3ddf87d5&quot;,&quot;values&quot;:&quot;[D@719b7309&quot;},{&quot;size&quot;:1000,&quot;indices&quot;:&quot;[I@63775cb5&quot;,&quot;values&quot;:&quot;[D@34c8d0f7&quot;},{&quot;size&quot;:1000,&quot;indices&quot;:&quot;[I@75e81894&quot;,&quot;values&quot;:&quot;[D@5f413e1b&quot;},{&quot;size&quot;:1000,&quot;indices&quot;:&quot;[I@68a53b2&quot;,&quot;values&quot;:&quot;[D@74b774fc&quot;},{&quot;size&quot;:1000,&quot;indices&quot;:&quot;[I@412eee46&quot;,&quot;values&quot;:&quot;[D@17c9a19e&quot;},{&quot;size&quot;:1000,&quot;indices&quot;:&quot;[I@438a6716&quot;,&quot;values&quot;:&quot;[D@c55fb0f&quot;},{&quot;size&quot;:1000,&quot;indices&quot;:&quot;[I@3abf781d&quot;,&quot;values&quot;:&quot;[D@60a0fb85&quot;}],&quot;genId&quot;:&quot;94118448&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/tableChart'], \n      function(playground, _magictableChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magictableChart,\n    \"o\": {\"headers\":[\"size\",\"indices\",\"values\"],\"nrow\":10,\"shown\":10,\"width\":600,\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    </div></div></div></div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 8
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "import org.apache.spark.mllib.clustering.KMeans\n\nval numClusters = 20\nval numIterations = 30\n\nval model = KMeans.train(vectors, numClusters, numIterations)\nval clusterRDD = sparkContext.makeRDD(model.clusterCenters, numClusters)",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark.mllib.clustering.KMeans\nnumClusters: Int = 20\nnumIterations: Int = 30\nmodel: org.apache.spark.mllib.clustering.KMeansModel = org.apache.spark.mllib.clustering.KMeansModel@23a3a1f3\nclusterRDD: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = ParallelCollectionRDD[98] at makeRDD at <console>:90\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "ParallelCollectionRDD[98] at makeRDD at &lt;console&gt;:90"
      },
      "output_type" : "execute_result",
      "execution_count" : 9
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "import org.apache.spark.mllib.linalg.DenseVector\nimport java.util.concurrent.atomic.AtomicInteger\n                                      \nval clusterRDD: RDD[Vector] = sc.makeRDD(model.clusterCenters, numClusters)\n\n\n\n\nval clusterRDDPair = clusterRDD.map(vector => {\n  vector.toDense.toArray.toList\n}).zipWithIndex\n\nclusterRDDPair.saveToCassandra(\"tweet_db\", \"cluster_vectors\", SomeColumns(\"values\", \"vector_id\"))\n\nclusterRDDPair.count",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark.mllib.linalg.DenseVector\nimport java.util.concurrent.atomic.AtomicInteger\nclusterRDD: org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector] = ParallelCollectionRDD[99] at makeRDD at <console>:96\nclusterRDDPair: org.apache.spark.rdd.RDD[(List[Double], Long)] = ZippedWithIndexRDD[101] at zipWithIndex at <console>:103\nres8: Long = 20\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "20"
      },
      "output_type" : "execute_result",
      "execution_count" : 10
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val some_tweets = texts.take(10)\n\nfor (i <- 0 until numClusters) {\n      println(s\"\\nCLUSTER $i:\")\n      some_tweets.foreach { t =>\n        if (model.predict(featurize(t)) == i) {\n          println(t)\n        }\n      }\n    }\n",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "\nCLUSTER 0:\nRT @Gwonam: Hello Twitter! #myfirstTweet\nIn lunch by myself today 😑👐\n\nCLUSTER 1:\n\nCLUSTER 2:\n\nCLUSTER 3:\n\nCLUSTER 4:\n\nCLUSTER 5:\n\nCLUSTER 6:\n\nCLUSTER 7:\n\nCLUSTER 8:\n\nCLUSTER 9:\n\nCLUSTER 10:\nRT @__737__: الإستغفار حياة الرُوح فكلما زَاد الإستغفار نَمتْ سعادتنا وتحقَقت أمنيَاتُنا * استغفر الله العظيم\nاللهم بك أمسينا، وبك أصبحنا، وبك نحيا، وبك نموت وإليك المصير . #أذكار_الصباح_والمساء #الترمذي #hadith\nRT @Diinnaah_: ماتسمحش لحد يعمل مقارنة بينك و بين شخص تاني اياً كان مين فيكوا احسن.\n\nCLUSTER 11:\n\nCLUSTER 12:\n\nCLUSTER 13:\n@hometownoffic I ain't gonna be there 👺\n@BeckyLynchGuyx is that not in like 20 minutes?\n\nCLUSTER 14:\n\nCLUSTER 15:\nRT @istanbulltd: @KukreyenKurba @YUSUFYAKUB622 Allah'ın adıyla basla sen bu kitaba. Pirense doncen aq http://t.co/7xnlMlWkOw\nSaya salah satunya,, kwkw\"@tetyedeswita: Pecinta paling tulus tak pernah menuntut agar orang yang ia cintai segera memahami perasaannya. :)\"\n\nCLUSTER 16:\n\nCLUSTER 17:\n\nCLUSTER 18:\nFirst episode of Wabbit was alright. First short suffered from being very predictable though\n\nCLUSTER 19:\nsome_tweets: Array[String] = Array(RT @istanbulltd: @KukreyenKurba @YUSUFYAKUB622 Allah'ın adıyla basla sen bu kitaba. Pirense doncen aq http://t.co/7xnlMlWkOw, Saya salah satunya,, kwkw\"@tetyedeswita: Pecinta paling tulus tak pernah menuntut agar orang yang ia cintai segera memahami perasaannya. :)\", First episode of Wabbit was alright. First short suffered from being very predictable though, @hometownoffic I ain't gonna be there 👺, RT @Gwonam: Hello Twitter! #myfirstTweet, In lunch by myself today 😑👐, RT @__737__: الإستغفار حياة الرُوح فكلما زَاد الإستغفار نَمتْ سعادتنا وتحقَقت أمنيَاتُنا * استغفر الله العظيم, اللهم بك أمسينا، وبك أصبحنا، وبك نحيا، وبك نموت وإليك المصير . #أذكار_الصباح_والمساء #الترمذي #hadith, @BeckyLynchGuyx is that not in like 20 minutes?, RT @Diinnaah_: ماتسمحش..."
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 11
    } ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true
    },
    "cell_type" : "code",
    "source" : "vector.take(0)",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true
    },
    "cell_type" : "code",
    "source" : "",
    "outputs" : [ ]
  } ],
  "nbformat" : 4
}